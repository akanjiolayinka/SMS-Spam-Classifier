{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a765bee2-f026-4da4-afcb-ede259208af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0493534b-a942-42a3-bd94-da16ab762b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/User/OneDrive/Desktop/SMS_SPAM_CLASSIFIER'), True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()   # goes out of /notebooks to root folder\n",
    "\n",
    "DATA_RAW = BASE_DIR / \"data\" / \"raw\" / \"spam.csv\"\n",
    "TRAIN_OUT = BASE_DIR / \"data\" / \"processed\" / \"train.csv\"\n",
    "TEST_OUT = BASE_DIR / \"data\" / \"processed\" / \"test.csv\"\n",
    "MODEL_DIR = BASE_DIR / \"models\"\n",
    "\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "BASE_DIR, DATA_RAW.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13f5f5d-3501-474b-a2fc-64d129ae7f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(DATA_RAW, encoding=\"latin-1\")\n",
    "\n",
    "# See the columns\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b24903-2ff3-426a-9787-9916025fa47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   label                                               text\n",
       " 0      0  Go until jurong point, crazy.. Available only ...\n",
       " 1      0                      Ok lar... Joking wif u oni...\n",
       " 2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       " 3      0  U dun say so early hor... U c already then say...\n",
       " 4      0  Nah I don't think he goes to usf, he lives aro...,\n",
       " label\n",
       " 0    4825\n",
       " 1     747\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the label and text columns\n",
    "if \"v1\" in df.columns and \"v2\" in df.columns:\n",
    "    df = df[[\"v1\", \"v2\"]]\n",
    "    df.columns = [\"label\", \"text\"]\n",
    "\n",
    "# Drop any missing rows\n",
    "df = df.dropna(subset=[\"label\", \"text\"])\n",
    "\n",
    "# Map ham/spam to 0/1\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "df.head(), df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63bb47ac-f4e3-4aa3-baae-b08ffde88765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                   text  label\n",
       " 184                          Going on nothing great.bye      0\n",
       " 2171                      I wont. So wat's wit the guys      0\n",
       " 5422            Ok k..sry i knw 2 siva..tats y i askd..      0\n",
       " 4113  Where are you ? What do you do ? How can you s...      0\n",
       " 4588       Have you not finished work yet or something?      0,\n",
       "                                                    text  label\n",
       " 2826  Oh right, ok. I'll make sure that i do loads o...      0\n",
       " 3695                     I am in tirupur.  call you da.      0\n",
       " 3906             No that just means you have a fat head      0\n",
       " 575   You have won ?1,000 cash or a ?2,000 prize! To...      1\n",
       " 2899  Come aftr  &lt;DECIMAL&gt; ..now i m cleaning ...      0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"],\n",
    "    df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "train_df = pd.DataFrame({\"text\": X_train, \"label\": y_train})\n",
    "test_df = pd.DataFrame({\"text\": X_test, \"label\": y_test})\n",
    "\n",
    "train_df.to_csv(TRAIN_OUT, index=False)\n",
    "test_df.to_csv(TEST_OUT, index=False)\n",
    "\n",
    "train_df.head(), test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af164ac5-32dc-4cba-852d-a3266de1f0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "input_dim = X_train_vec.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebfae070-c6f1-4829-8760-178177988001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 5000), (1115, 5000))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_dense = X_train_vec.toarray().astype(\"float32\")\n",
    "X_test_dense = X_test_vec.toarray().astype(\"float32\")\n",
    "\n",
    "y_train_arr = y_train.values.astype(\"float32\")\n",
    "y_test_arr = y_test.values.astype(\"float32\")\n",
    "\n",
    "X_train_dense.shape, X_test_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65cec7c0-9077-46a9-96c4-7b4acf88fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c7d74db-61ad-4f2d-8845-df64799d0efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 1115)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SpamDataset(X_train_dense, y_train_arr)\n",
    "test_dataset  = SpamDataset(X_test_dense, y_test_arr)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=128, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a13612a-5061-4322-b895-f842bc6cec20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd022201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the PyTorch model\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpamNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "# Ensure input_dim is available\n",
    "input_dim = X_train_dense.shape[1]\n",
    "input_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae4585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model, loss, optimizer, device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "model = SpamNet(input_dim=input_dim, hidden_dim=128, dropout=0.3).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa85876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & eval helper functions\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def eval_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return acc, all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05e46216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.5573 | Val Acc: 0.9166\n",
      "Epoch 2/10 | Loss: 0.1986 | Val Acc: 0.9722\n",
      "Epoch 3/10 | Loss: 0.0778 | Val Acc: 0.9821\n",
      "Epoch 4/10 | Loss: 0.0449 | Val Acc: 0.9848\n",
      "Epoch 5/10 | Loss: 0.0297 | Val Acc: 0.9848\n",
      "Epoch 6/10 | Loss: 0.0214 | Val Acc: 0.9848\n",
      "Epoch 7/10 | Loss: 0.0164 | Val Acc: 0.9848\n",
      "Epoch 8/10 | Loss: 0.0119 | Val Acc: 0.9857\n",
      "Epoch 9/10 | Loss: 0.0094 | Val Acc: 0.9857\n",
      "Epoch 10/10 | Loss: 0.0078 | Val Acc: 0.9857\n",
      "Best validation accuracy: 0.9856502242152466\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_acc, _, _ = eval_epoch(model, test_loader, device)\n",
    "    best_acc = max(best_acc, val_acc)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} | Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"Best validation accuracy:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adcd275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9856502242152466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99       966\n",
      "         1.0       0.99      0.91      0.94       149\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.95      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[964,   2],\n",
       "       [ 14, 135]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detailed evaluation\n",
    "val_acc, labels, preds = eval_epoch(model, test_loader, device)\n",
    "\n",
    "print(\"Final Accuracy:\", val_acc)\n",
    "print(classification_report(labels, preds))\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac1aae3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spam', 0.9811213612556458)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function to test a custom message\n",
    "def predict_text(text: str):\n",
    "    vec = vectorizer.transform([text])\n",
    "    X = vec.toarray().astype(\"float32\")\n",
    "    X_tensor = torch.from_numpy(X).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_tensor)\n",
    "        prob_spam = torch.sigmoid(logits).item()\n",
    "    \n",
    "    label = \"spam\" if prob_spam >= 0.5 else \"ham\"\n",
    "    return label, prob_spam\n",
    "\n",
    "predict_text(\"You have won 10 million dollars! Click this link now.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e2f84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('../models/spam_torch_model.pt'),\n",
       " WindowsPath('../models/tfidf_vectorizer.joblib'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model and vectorizer\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "MODEL_DIR = Path(\"..\") / \"models\"\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"spam_torch_model.pt\"\n",
    "VECTORIZER_PATH = MODEL_DIR / \"tfidf_vectorizer.joblib\"\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "joblib.dump(vectorizer, VECTORIZER_PATH)\n",
    "\n",
    "MODEL_PATH, VECTORIZER_PATH\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
